{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#--Here I made a simple program with basic concept for removing prepostition in   Nepali language words..\n",
    "#-- However I struggled on finding resources to learn as there are limited availability for Nepali language.. like PoS, lemmantizer, Tagging\n",
    "\n",
    "#--Also I tried to make own corpus, but that seem to consume more time.\n",
    "   \n",
    "#-- this is sample test of working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-- Regular expression operations module re\n",
    "import re\n",
    "\n",
    "class Tokenizer:\n",
    "    \"\"\"Base class for all tokenizers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # We need this for the build_repr to work properly in py2.7\n",
    "        pass\n",
    "\n",
    "    def sentence_tokenize(self, text):\n",
    "        \"\"\"\n",
    "        :param text: text to split into sentences\n",
    "        :return: a tokenized sentences from the text\n",
    "        \"\"\"\n",
    "\n",
    "        return re.split('(?<=[।?!]) +', text)\n",
    "\n",
    "    def word_tokenize(self, text):\n",
    "        \"\"\"Tokenizes text into words\n",
    "        Parameter\n",
    "        --------\n",
    "        text: text to split into words\n",
    "        Returns\n",
    "        -------\n",
    "        words: non-ascii array of words\n",
    "        \"\"\"\n",
    "        colon_lexicon = ['अंशत:', 'मूलत:', 'सर्वत:', 'प्रथमत:', 'सम्भवत:', 'सामान्यत:', 'विशेषत:', 'प्रत्यक्षत:',\n",
    "        'मुख्यत:', 'स्वरुपत:', 'अन्तत:', 'पूर्णत:', 'फलत:', 'क्रमश:', 'अक्षरश:', 'प्रायश:',\n",
    "        'कोटिश:', 'शतश:', 'शब्दश:']\n",
    "\n",
    "        # Handling punctuations: , \" ' ) ( { } [ ] ! ‘ ’ “ ” :- ? । / —\n",
    "        text = re.sub('\\,|\\\"|\\'| \\)|\\(|\\)| \\{| \\}| \\[| \\]|!|‘|’|“|”| \\:-|\\?|।|/|\\—', ' ', text)\n",
    "        words_original = text.split()\n",
    "\n",
    "        words = []\n",
    "        for word in words_original:\n",
    "            if word[len(word) - 1:] == '-':\n",
    "                if not word == '-':\n",
    "                    words.append(word[:len(word) - 1])\n",
    "            else:\n",
    "                if word[len(word) - 1:] == ':' and word not in colon_lexicon:\n",
    "                    words.append(word[:len(word) - 1])\n",
    "                else:\n",
    "                    words.append(word)\n",
    "\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text1 =\"आमाको सपना घर बनाउनु थियो । आमाले घरको काम गर्नु हुन्छ । घरमा हेर्नु हुन्छ ।\"\n",
    "text=\"काठमाडौँ — नेपालीको राष्ट्रियता नेपाली हो भन्नेमा दुईमत भएन । राष्ट्रियता उल्लेख गर्नुपर्ने फाराम भर्दा राष्ट्रभाषा ‘नेपाली’ उल्लेख गर्ने गरिन्छ, भलै रोमन लिपिमा किन नहोस् । नेपाली हुनुको गर्व होस् या नहोस् लेखिटोपल्ने हो । धन्न अंग्रेजले शासन नजमाएको देश हो, नेपाल। तर गणतन्त्र नेपालमा अंग्रेजीले चाही खर्लप्पै खाँने देखा परेको छ। सायद संविधानले नै ‘नेपालमा बोलिने सबै मातृभाषाहरु राष्ट्रभाषा हुन्' भनेको र त्यसमा मुलुकमा बोलिने १२३ भाषाको विवरणमा अंग्रेजी परेकाले जनप्रतिनिधिहरु अंग्रेजी भाषालाई सबैको मातृभाषा बनाउन कस्सिदै छन्।\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['काठमाडौँ',\n",
       " 'नेपालीको',\n",
       " 'राष्ट्रियता',\n",
       " 'नेपाली',\n",
       " 'हो',\n",
       " 'भन्नेमा',\n",
       " 'दुईमत',\n",
       " 'भएन',\n",
       " 'राष्ट्रियता',\n",
       " 'उल्लेख',\n",
       " 'गर्नुपर्ने',\n",
       " 'फाराम',\n",
       " 'भर्दा',\n",
       " 'राष्ट्रभाषा',\n",
       " 'नेपाली',\n",
       " 'उल्लेख',\n",
       " 'गर्ने',\n",
       " 'गरिन्छ',\n",
       " 'भलै',\n",
       " 'रोमन',\n",
       " 'लिपिमा',\n",
       " 'किन',\n",
       " 'नहोस्',\n",
       " 'नेपाली',\n",
       " 'हुनुको',\n",
       " 'गर्व',\n",
       " 'होस्',\n",
       " 'या',\n",
       " 'नहोस्',\n",
       " 'लेखिटोपल्ने',\n",
       " 'हो',\n",
       " 'धन्न',\n",
       " 'अंग्रेजले',\n",
       " 'शासन',\n",
       " 'नजमाएको',\n",
       " 'देश',\n",
       " 'हो',\n",
       " 'नेपाल',\n",
       " 'तर',\n",
       " 'गणतन्त्र',\n",
       " 'नेपालमा',\n",
       " 'अंग्रेजीले',\n",
       " 'चाही',\n",
       " 'खर्लप्पै',\n",
       " 'खाँने',\n",
       " 'देखा',\n",
       " 'परेको',\n",
       " 'छ',\n",
       " 'सायद',\n",
       " 'संविधानले',\n",
       " 'नै',\n",
       " 'नेपालमा',\n",
       " 'बोलिने',\n",
       " 'सबै',\n",
       " 'मातृभाषाहरु',\n",
       " 'राष्ट्रभाषा',\n",
       " 'हुन्',\n",
       " 'भनेको',\n",
       " 'र',\n",
       " 'त्यसमा',\n",
       " 'मुलुकमा',\n",
       " 'बोलिने',\n",
       " '१२३',\n",
       " 'भाषाको',\n",
       " 'विवरणमा',\n",
       " 'अंग्रेजी',\n",
       " 'परेकाले',\n",
       " 'जनप्रतिनिधिहरु',\n",
       " 'अंग्रेजी',\n",
       " 'भाषालाई',\n",
       " 'सबैको',\n",
       " 'मातृभाषा',\n",
       " 'बनाउन',\n",
       " 'कस्सिदै',\n",
       " 'छन्']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---break sentences to words wise, tokenize them\n",
    "Tokenizer.word_tokenize('',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'थियो', 'एक', 'या', 'तपाई', 'फेरी', 'वास्तवमा', 'नौ', 'तुरुन्तै', 'पर्छ', 'लागि', 'पूर्व', 'हुन्', 'नि', 'यी', 'भित्र', 'र', 'कहिलेकाहीं', 'नजिकै', 'यहाँसम्म', 'मा', 'भित्री', 'साँच्चै', 'गर्दै', 'मेरो', 'सधै', 'तेस्रो', 'गरि', 'तिर', 'अनुसार', 'कतै', 'संगै', 'बने', 'माथि', 'तापनी', 'यति', 'आदि', 'एउटै', 'भन्', 'तदनुसार', 'छैन', 'हुने', 'देखे', 'गरेको', 'गैर', 'पनि', 'नै', 'जसमा', 'पहिल्यै', 'सक्छ', 'जहाँ', 'उदाहरण', 'म', 'निम्नानुसार', 'जसले', 'यसो', 'त्यो', 'छौं', 'मात्र', 'गरौं', 'दुई', 'सही', 'गर्ने', 'पछि', 'आत्म', 'बीचमा', 'पहिले', 'बिरुद्ध', 'छ', 'औं', 'त', 'जाहिर', 'पटक', 'बिशेष', 'जस्तोसुकै', 'सायद', 'राखे', 'यस', 'कृपया', 'भन्छन्', 'सात', 'केही', 'राख्छ', 'पछिल्लो', 'उनको', 'साथै', 'अरुलाई', 'छन्', 'बाहिर', 'यथोचित', 'कसरी', 'त्सैले', 'पक्कै', 'रही', 'थिएन', 'देखेर', 'मुख्य', 'समय', 'स्पष्ट', 'निर्दिष्ट', 'पाँच', 'अगाडी', 'तिमी', 'कोही', 'देखियो', 'भने', 'तर', 'जान', 'निम्ति', 'गर्छ', 'ओठ', 'छु', 'जुन', 'कहाँबाट', 'अन्यत्र', 'भए', 'सो', 'जसबाट', 'क्रमशः', 'कुरा', 'अन्यथा', 'ठीक', 'संग', 'कि', 'गर्छु', 'बाहेक', 'का', 'यसपछि', 'कसैले', 'को', 'दोस्रो', 'सबैलाई', 'त्सपछि', 'जस्तो', 'गयौ', 'अलग', 'अन्य', 'ले', 'मलाई', 'यसरी', 'आयो', 'लगभग', 'अब', 'सम्भव', 'हरे', 'भन्छु', 'जबकि', 'राम्रो', 'कसै', 'दिए', 'प्रतेक', 'अन्तर्गत', 'बीच', 'तल', 'गर्नु', 'चाले', 'चार', 'यो', 'चाहनुहुन्छ', 'हो', 'सट्टा', 'आए', 'गर्न', 'कम से कम', 'उप', 'तिनिहरुलाई', 'जो', 'पक्का', 'यहाँ', 'रहेका', 'जे', 'भएको', 'किनभने', 'पर्याप्त', 'गर्नुपर्छ', 'यस्तो', 'चाहन्छु', 'उनले', 'यसको', 'हुन', 'तत्काल', 'भन्नुभयो', 'उहालाई', 'भन्दा', 'भर', 'गरी', 'निम्न', 'तपाईको', 'रूप', 'एकदम', 'देखि', 'धेरै', 'तथा', 'वरीपरी', 'सबै', 'सारा', 'पर्थ्यो', 'अर्थात', 'हरेक', 'अक्सर', 'रहेको', 'तिनीहरू', 'तेस्कारण', 'यद्यपि', 'जब', 'आफ्नो', 'जताततै', 'प्रति', 'आजको', 'नत्र', 'थिए', 'किन', 'अर्थात्', 'आफू', 'आफूलाई', 'लाई', 'सम्म', 'अर्को', 'गए', 'तीन', 'अरु', 'भन्ने', 'पहिलो', 'नयाँ', 'चाहिए', 'गरेका', 'ती', 'देखिन्छ', 'सोही', 'दिनुभएको', 'यदि', 'दिनुहुन्छ', 'जसलाई', 'पाँचौं', 'तिनी', 'बरु', 'छू', 'भन', 'प्लस', 'अझै', 'शायद', 'जस्तै', 'बारे', 'आफ्नै', 'जसको', 'यसबाहेक', 'देखेको', 'साथ', 'न', 'कुनै', 'के', 'तिनीहरुको', 'हुन्छ', 'त्यहाँ', 'गरेर'}\n"
     ]
    }
   ],
   "source": [
    "##---stop words are like \"is, am, are, the, to\"...\n",
    "stop_words = set(nltk.corpus.stopwords.words('nepali'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['काठमाडौँ', 'नेपालीको', 'राष्ट्रियता', 'नेपाली', 'भन्नेमा', 'दुईमत', 'भएन', 'राष्ट्रियता', 'उल्लेख', 'गर्नुपर्ने', 'फाराम', 'भर्दा', 'राष्ट्रभाषा', 'नेपाली', 'उल्लेख', 'गरिन्छ', 'भलै', 'रोमन', 'लिपिमा', 'नहोस्', 'नेपाली', 'हुनुको', 'गर्व', 'होस्', 'नहोस्', 'लेखिटोपल्ने', 'धन्न', 'अंग्रेजले', 'शासन', 'नजमाएको', 'देश', 'नेपाल', 'गणतन्त्र', 'नेपालमा', 'अंग्रेजीले', 'चाही', 'खर्लप्पै', 'खाँने', 'देखा', 'परेको', 'संविधानले', 'नेपालमा', 'बोलिने', 'मातृभाषाहरु', 'राष्ट्रभाषा', 'भनेको', 'त्यसमा', 'मुलुकमा', 'बोलिने', '१२३', 'भाषाको', 'विवरणमा', 'अंग्रेजी', 'परेकाले', 'जनप्रतिनिधिहरु', 'अंग्रेजी', 'भाषालाई', 'सबैको', 'मातृभाषा', 'बनाउन', 'कस्सिदै']\n"
     ]
    }
   ],
   "source": [
    "#--removing stop words\n",
    "words=Tokenizer.word_tokenize('',text)\n",
    "#define a list to add\n",
    "filtered_sentence=[]\n",
    "\n",
    "#---for stop words that occur many times and have less value, remove them\n",
    "#--and finally add them in array. filtered_sentence\n",
    "for w in words:\n",
    "    if w not in stop_words:\n",
    "        \n",
    "        filtered_sentence.append(w)\n",
    "        \n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'काठमाडौँ'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--check the word in filtered sentence\n",
    "word=filtered_sentence[0]\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "काठमाडौँ\n",
      "नेपाली\n",
      "राष्ट्रियता\n",
      "नेपाली\n",
      "भन्नेमा\n",
      "दुईमत\n",
      "भएन\n",
      "राष्ट्रियता\n",
      "उल्लेख\n",
      "गर्नुपर्\n",
      "फाराम\n",
      "भर्दा\n",
      "राष्ट्रभाषा\n",
      "नेपाली\n",
      "उल्लेख\n",
      "गरिन्छ\n",
      "भलै\n",
      "रोमन\n",
      "लिपिमा\n",
      "नहोस्\n",
      "नेपाली\n",
      "हुनु\n",
      "गर्व\n",
      "होस्\n",
      "नहोस्\n",
      "लेखिटोपल्\n",
      "धन्न\n",
      "अंग्रेज\n",
      "शासन\n",
      "नजमाए\n",
      "देश\n",
      "नेपाल\n",
      "गणतन्त्र\n",
      "नेपालमा\n",
      "अंग्रेजी\n",
      "चाही\n",
      "खर्लप्पै\n",
      "खाँ\n",
      "देखा\n",
      "परे\n",
      "संविधान\n",
      "नेपालमा\n",
      "बोलि\n",
      "मातृभाषाह\n",
      "राष्ट्रभाषा\n",
      "भने\n",
      "त्यसमा\n",
      "मुलुकमा\n",
      "बोलि\n",
      "१२३\n",
      "भाषा\n",
      "विवरणमा\n",
      "अंग्रेजी\n",
      "परेका\n",
      "जनप्रतिनिधिह\n",
      "अंग्रेजी\n",
      "भाषालाई\n",
      "सबै\n",
      "मातृभाषा\n",
      "बनाउन\n",
      "कस्सिदै\n"
     ]
    }
   ],
   "source": [
    "#--now filtered sentence to remove with prepositional symbols\n",
    "#--we can define many symbols and remove that symbol of paticular position\n",
    "for w in filtered_sentence:\n",
    "    if w.endswith((\"ो\", \"ु\", \"उ\", \"े\", \"ोै\") ):\n",
    "        print(w[:-2])\n",
    "    else:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As you can see the result have remove the signs, but also there are removing other range of signs too.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--\n",
    "1. We need PoS tagging to take out only noun and pronoun of the tokenize words\n",
    "2. As above remove the prepositional symbols\n",
    "3. Read Neapali file in Unicode format\n",
    "4. Append the file to existing one or save to new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''import codecs\n",
    "f = codecs.read('nepali_test.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    print(repr(line))\n",
    "\n",
    "f=open(\"nepali_text.txt\", \"a+\")\n",
    "f.write(\"Appended line %d\\r\\n\" % (i+1))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
